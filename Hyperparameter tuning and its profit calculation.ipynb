{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e5feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bcdf6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:Downloads/Telecom_customer churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b193fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9= pd.read_csv('C:\\\\Users\\\\neepa\\\\Downloads\\\\ProcessedData.csv')\n",
    "df_8= pd.read_csv('C:\\\\Users\\\\neepa\\\\Downloads\\\\churncol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc017879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78829, 133)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a7fbe4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LGBMClassier' from 'sklearn.ensemble' (C:\\Users\\neepa\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoostClassifier\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassier\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_iris\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LGBMClassier' from 'sklearn.ensemble' (C:\\Users\\neepa\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import your necessary dependencies\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import \\\n",
    "    r2_score, get_scorer\n",
    "from sklearn.linear_model import \\\n",
    "    Lasso, Ridge, LassoCV,LinearRegression\n",
    "from sklearn.preprocessing import \\\n",
    "    StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import \\\n",
    "    KFold, RepeatedKFold, GridSearchCV, \\\n",
    "    cross_validate, train_test_split\n",
    "\n",
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dfeb6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 63063\n",
      "X_test 15766\n",
      "y_train 63063\n",
      "y_test 15766\n"
     ]
    }
   ],
   "source": [
    "# dependent and independent variables were determined.\n",
    "X = df_9\n",
    "y = df_8['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "print(\"X_train\",len(X_train))\n",
    "print(\"X_test\",len(X_test))\n",
    "print(\"y_train\",len(y_train))\n",
    "print(\"y_test\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3cf7b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    " \n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1635043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6231764556640873"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction \n",
    "preds = classifier.predict(X_test) \n",
    "# check performance\n",
    "accuracy_score(preds,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76f1afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_churn = df_8['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a945befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_10=df_9.join(col_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ec7eec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asl_flag</th>\n",
       "      <th>refurb_new</th>\n",
       "      <th>truck</th>\n",
       "      <th>rv</th>\n",
       "      <th>ownrent</th>\n",
       "      <th>dwlltype</th>\n",
       "      <th>adults</th>\n",
       "      <th>infobase</th>\n",
       "      <th>numbcars</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnic_S</th>\n",
       "      <th>ethnic_U</th>\n",
       "      <th>ethnic_X</th>\n",
       "      <th>ethnic_Z</th>\n",
       "      <th>marital_B</th>\n",
       "      <th>marital_M</th>\n",
       "      <th>marital_S</th>\n",
       "      <th>marital_U</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  asl_flag  refurb_new  truck   rv  ownrent  dwlltype    adults  \\\n",
       "0         445       0.0         0.0    0.0  0.0      0.0  1.000000  1.000000   \n",
       "1         454       0.0         0.0    0.0  0.0      0.0  0.000000  1.000000   \n",
       "2         458       0.0         0.0    0.0  0.0      0.0  0.454545  0.636364   \n",
       "3         467       0.0         0.0    0.0  0.0      0.0  1.000000  1.000000   \n",
       "4         477       0.0         0.0    0.0  0.0      0.0  1.000000  2.000000   \n",
       "\n",
       "   infobase  numbcars  ...  ethnic_S  ethnic_U  ethnic_X  ethnic_Z  marital_B  \\\n",
       "0       0.0  0.636364  ...       0.0       0.0       0.0       0.0        0.0   \n",
       "1       2.0  0.363636  ...       0.0       1.0       0.0       0.0        0.0   \n",
       "2       2.0  0.636364  ...       0.0       1.0       0.0       0.0        0.0   \n",
       "3       0.0  0.454545  ...       0.0       0.0       0.0       0.0        0.0   \n",
       "4       0.0  1.000000  ...       0.0       0.0       0.0       1.0        0.0   \n",
       "\n",
       "   marital_M  marital_S  marital_U  ovrrev_Mean  churn  \n",
       "0        1.0        0.0        0.0     0.012632      1  \n",
       "1        0.0        0.0        1.0     0.000000      0  \n",
       "2        0.0        0.0        1.0     0.000000      1  \n",
       "3        0.0        0.0        0.0     0.002721      0  \n",
       "4        1.0        0.0        0.0     0.000000      0  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b24caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d36f381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b28db9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cfe0c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "72105a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.636\n"
     ]
    }
   ],
   "source": [
    "best_random.fit(X_train, y_train)\n",
    "y_pred1 = best_random.predict(X_test) # Predictions\n",
    "y_true1 = y_test # True values\n",
    "\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "983f723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.636\n",
      "Test precision: 0.6249\n",
      "Test recall: 0.6776\n",
      "Test F1 score: 0.6502\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true1, y_pred1), 4))\n",
    "print(\"Test precision:\", np.round(precision_score(y_true1, y_pred1), 4))\n",
    "print(\"Test recall:\", np.round(recall_score(y_true1, y_pred1), 4))\n",
    "print(\"Test F1 score:\", np.round(f1_score(y_true1, y_pred1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e56cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [20, 50, 70, 100],\n",
    "    'max_features': [11, 12],\n",
    "    'min_samples_leaf': [2, 3,4 ],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [300, 400, 500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfef6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 100,\n",
       " 'max_features': 12,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2aad6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6331\n",
      "Test precision: 0.6208\n",
      "Test recall: 0.6814\n",
      "Test F1 score: 0.6497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 4))\n",
    "print(\"Test precision:\", np.round(precision_score(y_true, y_pred), 4))\n",
    "print(\"Test recall:\", np.round(recall_score(y_true, y_pred), 4))\n",
    "print(\"Test F1 score:\", np.round(f1_score(y_true, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9494d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_9 = df_9.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ef53260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 63063\n",
      "X_test 15766\n",
      "y_train 63063\n",
      "y_test 15766\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "print(\"X_train\",len(X_train))\n",
    "print(\"X_test\",len(X_test))\n",
    "print(\"y_train\",len(y_train))\n",
    "print(\"y_test\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6151b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b04f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=43, verbose=2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "xgbc = xgb.XGBClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "xgbc_random = RandomizedSearchCV(estimator = xgbc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=43, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "xgbc_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b26f1a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "94ff0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random1 = xgbc_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ce3c94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random1.fit(X_train, y_train)\n",
    "y_pred2 = best_random.predict(X_test) # Predictions\n",
    "y_true2 = y_test # True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "72e1db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6331\n",
      "Test precision: 0.6208\n",
      "Test recall: 0.6814\n",
      "Test F1 score: 0.6497\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true2, y_pred2), 4))\n",
    "print(\"Test precision:\", np.round(precision_score(y_true2, y_pred2), 4))\n",
    "print(\"Test recall:\", np.round(recall_score(y_true2, y_pred2), 4))\n",
    "print(\"Test F1 score:\", np.round(f1_score(y_true2, y_pred2), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e150458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit(y, y_pred):\n",
    "    tp = np.where((y_pred==1) & (y==1), (5000-1000), 0)\n",
    "    fp = np.where((y_pred==1) & (y==0), -1000, 0)\n",
    "    return np.sum([tp,fp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "881c947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18131000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_profit(y_test,y_pred2)#XGBoost with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "987fc707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18131000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_profit(y_test,y_pred1)#RF with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "89876149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18176000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_profit(y_test,y_pred)  #RF with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880c0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
